# # cap = cv2.VideoCapture("rtsp://admin:admin@567@192.168.1.38:554/cam/realmonitor?channel=1&subtype=0", cv2.CAP_FFMPEG)
# # cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
# # img_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
# # img_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
# # prev = 0
# # second = 0
# # second = 0
# # bbox = [572, 552, 1696, 981]
# # total_time = 0
# # last_time = 0
# # calc_time = 0

# # while True:
# #     ret, frame = cap.read()
# #     if not ret: break

# #     if time.time()-prev > 1:
# #         prev = time.time()
# #         second +=1

# #         draw_box(frame, bbox)

# #         if second == 1:
# #             boxes_xyxy = first_inference(frame)
# #             person_feature = osnet_x1_model_output(frame, boxes_xyxy)
# #             index = select_person(frame, boxes_xyxy)
# #             track_feature = person_feature[index]
    
# #         else:
# #             boxes_xyxy = detr_model_output(frame,bbox)
# #             person_feature = osnet_x1_model_output(frame, boxes_xyxy)
# #             if person_feature is not None:
# #                 track_feature =  mark_person(updated_embedding, person_feature) 

# #         if track_feature is not None:
# #             box , updated_embedding = track_feature
# #             draw_box(frame, box)

# #             calc_time = second - last_time
# #             if calc_time < const.buffer_time:
# #                 total_time += calc_time
# #             last_time = second

# #         cv2.imshow("Live", frame)


# #     if cv2.waitKey(1) & 0xFF == ord('q'):
# #         break

# # cap.release()
# # cv2.destroyAllWindows()
# # print(second)
# # print(total_time)


# """
# robust_rtsp_capture.py

# A drop-tolerant RTSP reader + inference loop that follows the
# recommendations we discussed:
#   • forces TCP transport so packets are re-transmitted instead of dropped
#   • gives FFmpeg a roomier decode buffer
#   • pulls frames in a background thread and stores them in a bounded
#     queue so expensive CV/AI work never blocks the network socket
#   • drops excess frames to keep latency bounded
#   • keeps the rest of your business logic (first_inference / DETR /
#     OSNet re-id / tracking) exactly as you had it, just slotted into the
#     new reader pattern
# """
# import os
# import cv2
# import queue
# import threading
# import time

# # ------------------------------------------------------------
# # 1. Capture settings
# # ------------------------------------------------------------
# RTSP_URL = (
#     "rtsp://admin:admin@567@192.168.1.38:554/"
#     "cam/realmonitor?channel=1&subtype=0"
# )

# #  ── Force FFmpeg to pull over TCP (drops far fewer packets than UDP)
# #  ── Add a 5-second I/O timeout so .read() does not hang forever
# os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp|timeout;5000000"

# # How many decoded frames FFmpeg should buffer internally
# CAPTURE_BUFFER_SIZE = 60  # frames

# # How many frames we keep in the Python queue
# QUEUE_MAXSIZE = 60  # frames

# # ------------------------------------------------------------
# # 2. Open capture
# # ------------------------------------------------------------
# cap = cv2.VideoCapture(RTSP_URL, cv2.CAP_FFMPEG)
# cap.set(cv2.CAP_PROP_BUFFERSIZE, CAPTURE_BUFFER_SIZE)

# if not cap.isOpened():
#     raise RuntimeError(f"Unable to open RTSP stream: {RTSP_URL}")

# img_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
# img_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
# print(f"[camera] connected – resolution {img_w}×{img_h}")

# # ------------------------------------------------------------
# # 3. Background reader
# # ------------------------------------------------------------
# frame_q: "queue.Queue[cv2.typing.MatLike]" = queue.Queue(maxsize=QUEUE_MAXSIZE)


# def reader() -> None:
#     """Continuously read frames into the queue; drops if full."""
#     while True:
#         ok, frame = cap.read()
#         if not ok:
#             print("[reader] stream lost or cannot read – exiting reader thread")
#             break
#         try:
#             frame_q.put_nowait(frame)
#         except queue.Full:
#             # Queue is full – we are behind. Drop this frame to keep latency low.
#             pass


# t_reader = threading.Thread(target=reader, daemon=True)
# t_reader.start()

# # ------------------------------------------------------------
# # 4. Inference / tracking state
# # ------------------------------------------------------------
# bbox = [572, 552, 1696, 981]
# prev_ts = 0.0
# second = 0

# total_time = 0
# last_time = 0
# calc_time = 0

# track_feature = None
# updated_embedding = None

# # ------------------------------------------------------------
# # 5. Main processing loop
# # ------------------------------------------------------------
# try:
#     while True:
#         # blocks until a frame is available (reader keeps socket happy)
#         frame = frame_q.get()

#         now = time.time()
#         if now - prev_ts >= 1.0:  # run heavy logic ~1 Hz, like your original code
#             prev_ts = now
#             second += 1

#             draw_box(frame, bbox)  # static ROI marker

#             if second == 1:
#                 boxes_xyxy = first_inference(frame)
#                 person_feature = osnet_x1_model_output(frame, boxes_xyxy)
#                 index = select_person(frame, boxes_xyxy)
#                 track_feature = person_feature[index]
#                 updated_embedding = (
#                     track_feature[1] if track_feature is not None else None
#                 )
#             else:
#                 boxes_xyxy = detr_model_output(frame, bbox)
#                 person_feature = osnet_x1_model_output(frame, boxes_xyxy)
#                 if person_feature is not None:
#                     track_feature = mark_person(updated_embedding, person_feature)

#             if track_feature is not None:
#                 box, updated_embedding = track_feature
#                 draw_box(frame, box)

#                 calc_time = second - last_time
#                 if calc_time < const.buffer_time:
#                     total_time += calc_time
#                 last_time = second

#             cv2.imshow("Live", frame)

#         # Check for quit every loop (not tied to 1-Hz branch)
#         if cv2.waitKey(1) & 0xFF == ord("q"):
#             break
# finally:
#     cap.release()
#     cv2.destroyAllWindows()
#     t_reader.join(timeout=)

# print("seconds processed:", second)
# print("total_time:", total_time - 1)


import os
import cv2
import queue
import threading
import time